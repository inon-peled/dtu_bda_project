{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import pystan\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 16, 10\n",
    "COMMON_SEED = 1234\n",
    "\n",
    "def check_convergence(fit, also_print=False):\n",
    "    report = print\n",
    "    \n",
    "    def all_rhat_small_enough(fit):\n",
    "        return all(dict(fit.summary())['summary'][:, -1] < 1.1)\n",
    "    \n",
    "    def max_treedepth_exceeded(fit, max_depth = 10):\n",
    "        \"\"\"Check transitions that ended prematurely due to maximum tree depth limit\"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        depths = [x for y in sampler_params for x in y['treedepth__']]\n",
    "        n = sum(1 for x in depths if x == max_depth)\n",
    "        if n > 0:\n",
    "            report('Run again with max_depth set to a larger value to avoid saturation')        \n",
    "        N = len(depths)\n",
    "        report(('{} of {} iterations saturated the maximum tree depth of {}'\n",
    "               + ' ({}%)').format(n, N, max_depth, 100 * n / N))\n",
    "        return float(n) / N\n",
    "    \n",
    "    def e_bfmi_all_low_enough(fit):\n",
    "        \"\"\"\n",
    "        Checks the energy Bayesian fraction of missing information (E-BFMI).\n",
    "        E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
    "        \"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        for chain_num, s in enumerate(sampler_params):\n",
    "            energies = s['energy__']\n",
    "            numer = sum((energies[i] - energies[i - 1])**2 for i in range(1, len(energies))) / len(energies)\n",
    "            denom = np.var(energies)\n",
    "            if numer / denom < 0.2:\n",
    "                report('Chain {}: E-BFMI = {}'.format(chain_num, numer / denom))\n",
    "                report('E-BFMI below 0.2 indicates you may need to reparameterize your model')\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fraction_of_transitions_which_ended_with_divergence(fit):\n",
    "        \"\"\"Check transitions that ended with a divergence\"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        divergent = [x for y in sampler_params for x in y['divergent__']]\n",
    "        n = sum(divergent)\n",
    "        N = len(divergent)\n",
    "        report('{} of {} iterations ended with a divergence ({}%)'\n",
    "              .format(n, N, 100 * n / N))\n",
    "        if n > 0:\n",
    "            report('Try running with larger adapt_delta to remove the divergences')\n",
    "        return n / N\n",
    "    \n",
    "    convergence_results = {\n",
    "        \"all_rhat_small_enough(fit)\": all_rhat_small_enough(fit),\n",
    "        \"max_treedepth_exceeded(fit) < 0.02\": max_treedepth_exceeded(fit) < 0.02,\n",
    "        \"e_bfmi_all_low_enough(fit)\": e_bfmi_all_low_enough(fit),\n",
    "        \"fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3\": \n",
    "            fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3\n",
    "    }\n",
    "    report(convergence_results)\n",
    "    report(\"##### All convergence checks passed successfully. #####\" if all(convergence_results.values()) else\n",
    "          \"##### Some convergence checks failed, see above. #####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>births</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>8656</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>7724</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>362</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>12811</td>\n",
       "      <td>Monday</td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13634</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>11990</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  month  day  day_of_week  births weekday_name  day_of_year  \\\n",
       "2014-12-27  2014     12   27            6    8656     Saturday          361   \n",
       "2014-12-28  2014     12   28            7    7724       Sunday          362   \n",
       "2014-12-29  2014     12   29            1   12811       Monday          363   \n",
       "2014-12-30  2014     12   30            2   13634      Tuesday          364   \n",
       "2014-12-31  2014     12   31            3   11990    Wednesday          365   \n",
       "\n",
       "            week_of_year  \n",
       "2014-12-27            52  \n",
       "2014-12-28            52  \n",
       "2014-12-29             1  \n",
       "2014-12-30             1  \n",
       "2014-12-31             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births_2000s_df = pd.read_csv('US_births_2000-2014_SSA.csv')\n",
    "births_2000s_df_with_index = births_2000s_df\\\n",
    "    .rename(columns={'date_of_month': 'day'})\\\n",
    "    .set_index(pd.to_datetime(\n",
    "        births_2000s_df.rename(columns={'date_of_month': 'day'})\n",
    "        [['year', 'month', 'day']]))\\\n",
    "    .assign(weekday_name=lambda df: df.index.weekday_name)\\\n",
    "    .assign(day_of_year=lambda df: df.index.dayofyear)\\\n",
    "    .assign(week_of_year=lambda df: df.index.weekofyear)\n",
    "births_2000s_df_with_index.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11514.461538</td>\n",
       "      <td>1036.715902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12870.846154</td>\n",
       "      <td>790.289954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12762.269231</td>\n",
       "      <td>422.905919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12735.461538</td>\n",
       "      <td>813.567006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12524.500000</td>\n",
       "      <td>634.105530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9049.830189</td>\n",
       "      <td>344.643056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8014.433962</td>\n",
       "      <td>310.302366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean          std\n",
       "day_of_week                           \n",
       "1            11514.461538  1036.715902\n",
       "2            12870.846154   790.289954\n",
       "3            12762.269231   422.905919\n",
       "4            12735.461538   813.567006\n",
       "5            12524.500000   634.105530\n",
       "6             9049.830189   344.643056\n",
       "7             8014.433962   310.302366"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weekday_priors_by_year_2000():\n",
    "    df_2000 = births_2000s_df_with_index[lambda df: df.year == 2000]\n",
    "    return df_2000.groupby('day_of_week').agg(['mean', 'std']).births\n",
    "\n",
    "weekday_priors_by_year_2000()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>12481.507692</td>\n",
       "      <td>909.221295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>8532.132075</td>\n",
       "      <td>614.062616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean         std\n",
       "is_weekend                          \n",
       "False       12481.507692  909.221295\n",
       "True         8532.132075  614.062616"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def priors_for_weekend_vs_workday_by_year_2000():\n",
    "    df_2000 = births_2000s_df_with_index[lambda df: df.year == 2000]\n",
    "    return df_2000\\\n",
    "        .assign(is_weekend=lambda df: df.day_of_week.isin([6, 7]))\\\n",
    "        .groupby('is_weekend')\\\n",
    "        .agg(['mean', 'std'])\\\n",
    "        .births\n",
    "\n",
    "priors_for_weekend_vs_workday_by_year_2000()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_test': array([3, 4, 5, 6, 7, 1, 2]),\n",
       " 'x_train': array([1, 2, 3, ..., 7, 1, 2]),\n",
       " 'y_test': array([ 8018, 11171, 12317,  8199,  7174, 11400, 12310]),\n",
       " 'y_train': array([ 7663, 10635, 12449, ...,  7896, 13096, 12525])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_and_test_for_sliding_window(test_date):\n",
    "    num_data_points_before_first_test_date = datetime(2014, 1, 1) - datetime(2001, 1, 1)\n",
    "    df = births_2000s_df_with_index[['day_of_week', 'births']]\\\n",
    "        [lambda df: df.index <= test_date + timedelta(days=6)]\\\n",
    "        [lambda df: df.index >= test_date - num_data_points_before_first_test_date]\n",
    "    return {\n",
    "        'x_train': df.day_of_week[:-7].values,\n",
    "        'y_train': df.births[:-7].values,\n",
    "        'x_test': df.day_of_week[-7:].values,\n",
    "        'y_test': df.births[-7:].values\n",
    "    }\n",
    "        \n",
    "get_train_and_test_for_sliding_window(datetime(2014, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction_errors):\n",
    "    return (prediction_errors ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1f5534f9f16a420dad5dd0b0607ea807 NOW.\n"
     ]
    }
   ],
   "source": [
    "model_hier_negbin = pystan.StanModel(model_code='''\n",
    "data {\n",
    "    int<lower=0> T; // Number of predictions.\n",
    "    int<lower=0> N; // Number of data points.\n",
    "    int y_train[N]; // Train data points.\n",
    "    int y_test[T]; // Test data points, for log-likelihood.\n",
    "    int<lower=1,upper=7> x_train[N]; // Weekday indicator for each observed data point.\n",
    "    int<lower=1,upper=7> x_test[T]; // Weekday indicator for each prediction.\n",
    "    real<lower=0> prior_mean_weekend;\n",
    "    real<lower=0> prior_mean_workday;\n",
    "    real<lower=0> prior_std_weekend;\n",
    "    real<lower=0> prior_std_workday;\n",
    "    real<lower=0> V_lambda; // Std. dev. for priors on lambda.\n",
    "    real<lower=0> V_sigma; // Std. dev. for priors on sigma.\n",
    "    real<lower=0> V_phi; // Std. dev. for priors on phi.\n",
    "    real<lower=0> prior_phi;\n",
    "    real<lower=0> V_daily_phi;\n",
    "}\n",
    "parameters {\n",
    "    real<lower=0> common_phi;\n",
    "    real<lower=0> phi[7];\n",
    "    real<lower=0> mu[7];\n",
    "    real<lower=0> mu_weekend;\n",
    "    real<lower=0> mu_workday;\n",
    "    real<lower=0> sigma_weekend;\n",
    "    real<lower=0> sigma_workday;\n",
    "}\n",
    "model {\n",
    "    common_phi ~ normal(prior_phi, V_phi * prior_phi);\n",
    "    mu_weekend ~ normal(prior_mean_weekend, V_lambda * prior_std_weekend);\n",
    "    mu_workday ~ normal(prior_mean_workday, V_lambda * prior_std_workday);\n",
    "    sigma_weekend ~ normal(prior_std_weekend, V_sigma * prior_std_weekend);\n",
    "    sigma_workday ~ normal(prior_std_workday, V_sigma * prior_std_workday);\n",
    "    mu[6] ~ normal(mu_weekend, sigma_weekend);\n",
    "    mu[7] ~ normal(mu_weekend, sigma_weekend);\n",
    "    for (i in 1:5) {\n",
    "        mu[i] ~ normal(mu_workday, sigma_workday);\n",
    "    }\n",
    "    phi ~ cauchy(common_phi, V_daily_phi * common_phi);\n",
    "    y_train ~ neg_binomial_2(mu[x_train], phi[x_train]);\n",
    "}\n",
    "generated quantities {\n",
    "    real loglik;\n",
    "    vector[T] y_pred;\n",
    "    loglik = 0;\n",
    "    for (t in 1:T) {\n",
    "        y_pred[t] = neg_binomial_2_rng(mu[x_test[t]], phi[x_test[t]]);\n",
    "        loglik += neg_binomial_2_lpmf(y_test[t] | mu[x_test[t]], phi[x_test[t]]);\n",
    "    }\n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_stds:\n",
      "[1036.71590189  790.28995385  422.90591896  813.56700585  634.10553028\n",
      "  344.64305592  310.30236553]\n",
      "prior_mu:\n",
      "[11514.46153846 12870.84615385 12762.26923077 12735.46153846\n",
      " 12524.5         9049.83018868  8014.43396226]\n",
      "prior_phi:\n",
      "[124.69400825 270.82246617 980.66297605 249.85061788 402.66186638\n",
      " 746.37900747 727.64108437]\n"
     ]
    }
   ],
   "source": [
    "prior_stds = weekday_priors_by_year_2000()['std'].values\n",
    "prior_mu = weekday_priors_by_year_2000()['mean'].values\n",
    "prior_phi = (prior_mu ** 2) / (prior_stds ** 2 - prior_mu)\n",
    "print(\"prior_stds:\", prior_stds, \"prior_mu:\", prior_mu, \"prior_phi:\", prior_phi, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second week of 2014.\n",
    "data = get_train_and_test_for_sliding_window(datetime(2014, 1, 1) + timedelta(days=7))\n",
    "fit = model_hier_negbin.sampling(seed=COMMON_SEED, iter=500, data=dict(\n",
    "        V_daily_phi=0.02,\n",
    "        prior_phi=prior_phi.mean(),\n",
    "        V_phi=1,\n",
    "        V_lambda=4,\n",
    "        V_sigma=0.2,\n",
    "        prior_mean_weekend=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == True]['mean'].values[0],\n",
    "        prior_mean_workday=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == False]['mean'].values[0],\n",
    "        prior_std_workday=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == False]['std'].values[0],\n",
    "        prior_std_weekend=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == True]['std'].values[0],\n",
    "        x_train=data['x_train'],\n",
    "        x_test=data['x_test'],\n",
    "        y_train=data['y_train'],\n",
    "        y_test=data['y_test'],\n",
    "        T=7,\n",
    "        N=len(data['x_train'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_convergence(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(fit.extract()[\"y_pred\"].mean(axis=0) - data[\"y_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hier_negbin_data_extractor(data):\n",
    "    return dict(\n",
    "        V_daily_phi=0.02,\n",
    "        prior_phi=prior_phi.mean(),\n",
    "        V_phi=1,\n",
    "        V_lambda=4,\n",
    "        V_sigma=0.2,\n",
    "        prior_mean_weekend=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == True]['mean'].values[0],\n",
    "        prior_mean_workday=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == False]['mean'].values[0],\n",
    "        prior_std_workday=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == False]['std'].values[0],\n",
    "        prior_std_weekend=priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == True]['std'].values[0],\n",
    "        x_train=data['x_train'],\n",
    "        x_test=data['x_test'],\n",
    "        y_train=data['y_train'],\n",
    "        y_test=data['y_test'],\n",
    "        T=7,\n",
    "        N=len(data['x_train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stan_model_on_sliding_windows(iterations, stan_data_extractor, persist_path, stan_model, num_windows):\n",
    "    if not os.path.exists(persist_path):\n",
    "        os.mkdir(persist_path)\n",
    "    all_prediction_errors = []\n",
    "    for i in range(num_windows):\n",
    "        data = get_train_and_test_for_sliding_window(datetime(2014, 1, 1) + timedelta(days=i * 7))\n",
    "        fit = stan_model.sampling(seed=COMMON_SEED, data=stan_data_extractor(data), iter=iterations, chains=1,\n",
    "                                 control=dict(adapt_delta=0.99, max_treedepth=20))\n",
    "        print(fit)\n",
    "        check_convergence(fit, also_print=True)\n",
    "        pred_err = fit.extract()['y_pred'].mean(axis=0) - data['y_test']\n",
    "        all_prediction_errors.append(pred_err)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_summary.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit.summary(), f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_extract.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit.extract(), f)         \n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_pred_err.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(pred_err, f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_y_test.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(data['y_test'], f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit, f)                        \n",
    "    return rmse(np.concatenate(all_prediction_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    172.59    2.09  14.45 146.67 161.96 173.62 182.61 200.77     48   1.02\n",
      "phi[0]          85.4    0.31   4.45  76.37  82.86  85.14  88.14  95.15    206    1.0\n",
      "phi[1]        171.93    1.28   10.8 150.16  164.5  172.5 179.38 191.85     71   1.02\n",
      "phi[2]        184.56     0.9  10.77 162.58  178.5 184.23 191.35 206.66    142    1.0\n",
      "phi[3]          96.7    0.36   5.08   87.3  93.13   96.1 100.44 107.95    203    1.0\n",
      "phi[4]        146.36    0.76   9.33 127.32 140.39 145.84 151.99  164.3    152    1.0\n",
      "phi[5]        294.76    1.38  17.64  260.6  283.8 293.72 305.93  335.6    163    1.0\n",
      "phi[6]        387.63     2.0   21.1 342.52 375.37  387.6 399.48 429.88    111    1.0\n",
      "mu[0]          1.2e4    3.24   51.3  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4    2.37  37.41  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250   1.01\n",
      "mu[2]          1.3e4     2.3  36.41  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.54  55.96  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.44  38.62  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[5]         8539.3    1.22  19.21 8505.4 8525.7 8536.4 8553.3 8578.8    250    1.0\n",
      "mu[6]         7490.5    0.93  14.78 7462.2 7480.6 7490.6 7501.8 7518.0    250    1.0\n",
      "mu_weekend    8031.4   27.69 437.87 7129.7 7740.9 8038.1 8325.4 8867.4    250    1.0\n",
      "mu_workday     1.3e4   32.48 375.96  1.2e4  1.2e4  1.3e4  1.3e4  1.3e4    134    1.0\n",
      "sigma_weekend 629.31    7.78 122.98 378.71 560.03 634.23 701.13 896.43    250    1.0\n",
      "sigma_workday 834.93   12.93 168.12 525.81 726.21 831.45 950.35 1200.0    169    1.0\n",
      "loglik        -72.95    0.09   1.03 -74.99 -73.57 -72.91 -72.28 -70.87    139    1.0\n",
      "y_pred[0]      1.3e4   61.62 974.35  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[1]      1.3e4   88.56 1400.2  1.0e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[2]      1.3e4   73.38 1085.9  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    219    1.0\n",
      "y_pred[3]     8559.1   33.79 534.34 7505.4 8182.9 8576.0 8887.9 9580.3    250    1.0\n",
      "y_pred[4]     7479.0   25.76 399.93 6729.5 7195.9 7473.5 7782.4 8257.3    241    1.0\n",
      "y_pred[5]      1.2e4   85.12 1304.9 9558.6  1.1e4  1.2e4  1.3e4  1.5e4    235    1.0\n",
      "y_pred[6]      1.3e4   65.75 934.48  1.1e4  1.3e4  1.3e4  1.4e4  1.5e4    202   1.01\n",
      "lp__           4.5e8    0.37   3.59  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8     93    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:09:47 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inonpe/jupyter/dtu_bda_project/env/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 52s, sys: 470 ms, total: 5min 52s\n",
      "Wall time: 5min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2048.2154705814382"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Quick check: one time window.\n",
    "fit_stan_model_on_sliding_windows(\n",
    "    500,\n",
    "    hier_negbin_data_extractor,\n",
    "    'fit_hier_negbin_one_phi', \n",
    "    model_hier_negbin,\n",
    "    1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    172.59    2.09  14.45 146.67 161.96 173.62 182.61 200.77     48   1.02\n",
      "phi[0]          85.4    0.31   4.45  76.37  82.86  85.14  88.14  95.15    206    1.0\n",
      "phi[1]        171.93    1.28   10.8 150.16  164.5  172.5 179.38 191.85     71   1.02\n",
      "phi[2]        184.56     0.9  10.77 162.58  178.5 184.23 191.35 206.66    142    1.0\n",
      "phi[3]          96.7    0.36   5.08   87.3  93.13   96.1 100.44 107.95    203    1.0\n",
      "phi[4]        146.36    0.76   9.33 127.32 140.39 145.84 151.99  164.3    152    1.0\n",
      "phi[5]        294.76    1.38  17.64  260.6  283.8 293.72 305.93  335.6    163    1.0\n",
      "phi[6]        387.63     2.0   21.1 342.52 375.37  387.6 399.48 429.88    111    1.0\n",
      "mu[0]          1.2e4    3.24   51.3  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4    2.37  37.41  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250   1.01\n",
      "mu[2]          1.3e4     2.3  36.41  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.54  55.96  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.44  38.62  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[5]         8539.3    1.22  19.21 8505.4 8525.7 8536.4 8553.3 8578.8    250    1.0\n",
      "mu[6]         7490.5    0.93  14.78 7462.2 7480.6 7490.6 7501.8 7518.0    250    1.0\n",
      "mu_weekend    8031.4   27.69 437.87 7129.7 7740.9 8038.1 8325.4 8867.4    250    1.0\n",
      "mu_workday     1.3e4   32.48 375.96  1.2e4  1.2e4  1.3e4  1.3e4  1.3e4    134    1.0\n",
      "sigma_weekend 629.31    7.78 122.98 378.71 560.03 634.23 701.13 896.43    250    1.0\n",
      "sigma_workday 834.93   12.93 168.12 525.81 726.21 831.45 950.35 1200.0    169    1.0\n",
      "loglik        -72.95    0.09   1.03 -74.99 -73.57 -72.91 -72.28 -70.87    139    1.0\n",
      "y_pred[0]      1.3e4   61.62 974.35  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[1]      1.3e4   88.56 1400.2  1.0e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[2]      1.3e4   73.38 1085.9  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    219    1.0\n",
      "y_pred[3]     8559.1   33.79 534.34 7505.4 8182.9 8576.0 8887.9 9580.3    250    1.0\n",
      "y_pred[4]     7479.0   25.76 399.93 6729.5 7195.9 7473.5 7782.4 8257.3    241    1.0\n",
      "y_pred[5]      1.2e4   85.12 1304.9 9558.6  1.1e4  1.2e4  1.3e4  1.5e4    235    1.0\n",
      "y_pred[6]      1.3e4   65.75 934.48  1.1e4  1.3e4  1.3e4  1.4e4  1.5e4    202   1.01\n",
      "lp__           4.5e8    0.37   3.59  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8     93    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:15:53 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inonpe/jupyter/dtu_bda_project/env/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    168.02    1.41  11.71 145.97 160.16  168.2 176.37 189.26     69    1.0\n",
      "phi[0]         87.06    0.42   4.96  77.75  83.68   86.7  90.14  99.22    140   1.03\n",
      "phi[1]        170.31    0.95   9.45 152.03 163.23 170.23 177.36 188.32    100    1.0\n",
      "phi[2]        176.36    0.88   9.54 158.87 170.07 175.85 182.95 195.67    118    1.0\n",
      "phi[3]         95.86    0.39   5.32  85.55   92.1  95.95   99.8 106.21    182    1.0\n",
      "phi[4]        147.77    0.87   8.73 131.06 141.53 147.78 154.28 164.05    100    1.0\n",
      "phi[5]         296.4    1.05  16.53  266.6 284.34 296.46 308.11 329.64    250    1.0\n",
      "phi[6]        387.22    1.39  21.91 350.72 369.69 387.75 402.16 432.97    250   1.01\n",
      "mu[0]          1.2e4     3.7  58.47  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4    2.39  37.77  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[2]          1.3e4    1.99  31.48  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.46  54.67  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.56  40.52  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[5]         8539.4    1.25  19.74 8501.1 8525.0 8541.4 8553.2 8579.0    250   1.01\n",
      "mu[6]         7490.1    0.91  14.42 7462.8 7479.3 7490.4 7501.2 7515.0    250    1.0\n",
      "mu_weekend    7993.2    36.4 442.82 7137.6 7701.3 8001.7 8249.6 8951.7    148    1.0\n",
      "mu_workday     1.3e4   22.32 352.95  1.2e4  1.2e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "sigma_weekend 620.32   10.45 114.94 354.33 550.98 619.25 689.26 844.17    121    1.0\n",
      "sigma_workday 808.68   11.39 180.13  488.3 680.62 810.51 931.87 1188.8    250    1.0\n",
      "loglik        -55.09  5.2e-3   0.08 -55.26 -55.15 -55.09 -55.03 -54.93    250    1.0\n",
      "y_pred[0]      1.3e4   61.97 979.77  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[1]      1.3e4   84.58 1196.1  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    200    1.0\n",
      "y_pred[2]      1.3e4   71.16 1125.2  1.0e4  1.2e4  1.3e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[3]     8514.1   32.84  506.6 7595.2 8126.4 8509.0 8823.3 9489.5    238    1.0\n",
      "y_pred[4]     7497.6   23.84  377.0 6794.9 7213.9 7489.5 7765.1 8269.5    250    1.0\n",
      "y_pred[5]      1.2e4   79.18 1234.3 9571.8  1.1e4  1.2e4  1.3e4  1.4e4    243    1.0\n",
      "y_pred[6]      1.3e4   56.57 894.39  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250   1.01\n",
      "lp__           4.5e8    0.29   2.92  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8    100    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:22:16 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n",
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    171.11    1.56  11.57 149.79 163.03 170.67 178.52 193.65     55   1.01\n",
      "phi[0]         86.81    0.36   5.04  76.56  83.52  86.71  89.97  97.65    196    1.0\n",
      "phi[1]        171.46    1.01   9.13 155.21 165.42 171.16  178.3 189.76     82    1.0\n",
      "phi[2]         176.0    1.06   9.75 157.98 169.81 176.17 182.28 196.83     84    1.0\n",
      "phi[3]         96.44    0.44   5.44  85.58  92.47  96.97 100.85 106.06    152    1.0\n",
      "phi[4]        148.37    0.86   9.81 129.44 141.17 149.53 155.74 164.55    130    1.0\n",
      "phi[5]        295.59    1.71  19.47  264.7 282.89 294.17 306.58 339.74    129    1.0\n",
      "phi[6]        391.59    1.95  21.18 353.68 377.19 390.69 405.85 429.92    118    1.0\n",
      "mu[0]          1.2e4    3.75  59.33  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4     2.6  41.16  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[2]          1.3e4    2.25  35.51  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.31   52.3  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.55  40.36  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250   1.01\n",
      "mu[5]         8536.9    1.07  16.98 8503.7 8524.9 8536.2 8548.3 8570.5    250   1.01\n",
      "mu[6]         7487.3    1.04   16.4 7455.5 7476.6 7487.2 7497.3 7521.3    250    1.0\n",
      "mu_weekend    8029.7   32.04 506.59 6989.5 7727.7 8006.5 8320.7 9136.9    250    1.0\n",
      "mu_workday     1.3e4   24.93 394.19  1.2e4  1.3e4  1.3e4  1.3e4  1.4e4    250    1.0\n",
      "sigma_weekend 645.97    8.12 108.06 450.23 564.88 632.35 723.31  865.3    177    1.0\n",
      "sigma_workday 831.23    10.6 167.61 503.38 709.85 841.86 946.33 1139.3    250    1.0\n",
      "loglik        -56.78  7.1e-3   0.11 -57.01 -56.85 -56.78 -56.71 -56.56    247    1.0\n",
      "y_pred[0]      1.3e4   61.74 976.14  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250   1.01\n",
      "y_pred[1]      1.3e4   87.39 1299.1  1.0e4  1.2e4  1.3e4  1.4e4  1.6e4    221    1.0\n",
      "y_pred[2]      1.3e4   64.85 1025.4  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[3]     8489.8   36.49 514.69 7448.9 8132.0 8500.5 8832.2 9505.8    199    1.0\n",
      "y_pred[4]     7486.5   24.47 376.69 6751.3 7208.7 7514.0 7785.1 8142.3    237    1.0\n",
      "y_pred[5]      1.2e4   74.91 1184.3 9578.0  1.1e4  1.2e4  1.3e4  1.4e4    250    1.0\n",
      "y_pred[6]      1.3e4   64.78 866.67  1.1e4  1.3e4  1.3e4  1.4e4  1.5e4    179   1.01\n",
      "lp__           4.5e8    0.38   3.48  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8     82    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:34:09 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n",
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    169.01    1.15  11.03 147.05 161.56 169.31 176.51 193.41     92   1.01\n",
      "phi[0]          86.9     0.3   4.68  78.25  83.43  86.48  90.17  95.78    250    1.0\n",
      "phi[1]        170.16    0.87   9.28  152.3 163.71 170.22 176.29 188.92    114   1.01\n",
      "phi[2]        174.93    0.87   9.79 158.84 166.78 174.03 181.45 196.77    128    1.0\n",
      "phi[3]         96.41    0.48    6.1  86.06  91.93  96.38 100.52 110.64    164   1.02\n",
      "phi[4]        148.34    0.56   8.84 130.58 142.62 148.08 153.99 167.35    250   1.01\n",
      "phi[5]        298.02    1.23  15.75 267.37 285.13 297.74 310.07 328.31    164    1.0\n",
      "phi[6]        384.46     1.5  22.31 345.07 367.88 383.06 399.03 432.79    220    1.0\n",
      "mu[0]          1.2e4    3.19  50.37  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250   1.01\n",
      "mu[1]          1.3e4     2.4  37.95  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[2]          1.3e4    2.23   35.3  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    2.95  46.66  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.36  37.24  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[5]         8533.7    1.13  17.93 8500.9 8521.5 8533.2 8545.6 8567.6    250    1.0\n",
      "mu[6]         7486.6    0.96  15.15 7459.1 7475.9 7485.6 7497.4 7514.6    250   1.01\n",
      "mu_weekend    8047.6   30.86 437.58 7154.0 7784.9 8044.9 8304.1 8898.2    201    1.0\n",
      "mu_workday     1.3e4   20.74 325.99  1.2e4  1.2e4  1.3e4  1.3e4  1.3e4    247    1.0\n",
      "sigma_weekend 634.32    7.49 118.36 400.58 548.68 641.65 711.18 867.64    250    1.0\n",
      "sigma_workday 827.08   12.58 167.78 525.11 697.42 836.61 928.09 1158.1    178    1.0\n",
      "loglik        -55.39  5.3e-3   0.08 -55.55 -55.45 -55.39 -55.33 -55.22    250   1.01\n",
      "y_pred[0]      1.3e4   67.22 1062.8  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[1]      1.3e4   82.02 1275.9  1.0e4  1.2e4  1.3e4  1.4e4  1.5e4    242    1.0\n",
      "y_pred[2]      1.3e4   64.75 1023.7  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[3]     8563.4   31.37 493.03 7598.8 8219.9 8547.0 8893.1 9537.4    247    1.0\n",
      "y_pred[4]     7503.9   24.99 395.06 6785.9 7210.6 7548.0 7773.3 8209.3    250    1.0\n",
      "y_pred[5]      1.2e4   84.14 1330.3 9689.4  1.1e4  1.2e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[6]      1.3e4   68.97 997.14  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    209   1.01\n",
      "lp__           4.5e8    0.33   3.19  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8     93    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:37:54 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    171.94    1.03  10.13  150.3 165.77 172.88 177.77 192.96     96    1.0\n",
      "phi[0]         87.28    0.33   4.53  78.96  83.73  87.34  90.28  96.02    184    1.0\n",
      "phi[1]        172.18    0.78   8.51 156.13 165.89 173.16 177.61 186.93    118    1.0\n",
      "phi[2]        175.15    0.86   8.59 157.02 169.98 174.91 179.86 193.89     99    1.0\n",
      "phi[3]         96.33    0.35   5.51  86.99   92.0  96.13 100.31 107.64    250    1.0\n",
      "phi[4]         147.0    0.81   9.25 129.72 140.33 147.27 153.12 164.96    130   1.01\n",
      "phi[5]        296.99    1.11  17.53 263.94 284.95 295.86 309.32 332.52    250    1.0\n",
      "phi[6]        388.56    1.36  21.56 350.68  372.3  387.3 404.04 432.03    250    1.0\n",
      "mu[0]          1.2e4     2.9  45.84  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4    2.26  35.72  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[2]          1.3e4    2.37   37.5  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.13  49.57  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.53  39.28  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    242   1.02\n",
      "mu[5]         8535.8    1.29  20.42 8495.0 8521.1 8535.3 8549.1 8580.7    250    1.0\n",
      "mu[6]         7486.4    0.77  12.15 7464.1 7477.4 7485.2 7494.5 7511.7    250    1.0\n",
      "mu_weekend    8028.4   33.63 402.18 7270.4 7739.1 8067.1 8313.3 8730.8    143   1.04\n",
      "mu_workday     1.3e4   26.15 395.74  1.2e4  1.2e4  1.3e4  1.3e4  1.4e4    229    1.0\n",
      "sigma_weekend 626.54    8.28 123.93 392.86 547.27 618.56 711.19 903.36    224    1.0\n",
      "sigma_workday 816.28   12.69 200.19 458.23 676.63 793.88 958.95 1221.1    249    1.0\n",
      "loglik        -56.11  8.6e-3    0.1 -56.29 -56.18 -56.11 -56.04 -55.92    132    1.0\n",
      "y_pred[0]      1.3e4   68.18 1078.0  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[1]      1.3e4   82.01 1296.6  1.0e4  1.2e4  1.3e4  1.4e4  1.6e4    250    1.0\n",
      "y_pred[2]      1.3e4   66.35 1049.1  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[3]     8555.4   31.13 492.24 7679.5 8184.9 8553.5 8861.3 9515.6    250    1.0\n",
      "y_pred[4]     7471.0   24.97 394.85 6774.6 7211.7 7455.0 7711.2 8292.0    250    1.0\n",
      "y_pred[5]      1.2e4  104.24 1375.0 9708.3  1.1e4  1.2e4  1.3e4  1.5e4    174    1.0\n",
      "y_pred[6]      1.3e4   81.36 1051.3  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    167   1.02\n",
      "lp__           4.5e8     0.4   3.48  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8     77    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:46:13 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n",
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    170.27    0.88   8.57  154.7 163.73  170.2 176.04 186.49     95    1.0\n",
      "phi[0]          87.3    0.29    4.2  79.61  84.32  87.34  90.11  95.46    209    1.0\n",
      "phi[1]        171.01    0.74   7.85 156.46 165.35 171.31 176.35  186.4    112    1.0\n",
      "phi[2]        173.82    0.65   8.52 156.66 168.04 173.31 179.71 190.95    171    1.0\n",
      "phi[3]         96.56    0.44    5.7  86.47  92.15  96.45  100.4 108.21    170   1.01\n",
      "phi[4]        147.01    0.74   9.37 130.14 140.14 146.73 153.28 165.02    159    1.0\n",
      "phi[5]         294.7    1.06   16.7 263.65 283.62 294.12 306.22 327.35    250    1.0\n",
      "phi[6]        390.06    1.49   20.5 352.83 375.01 389.95 402.71 429.41    188    1.0\n",
      "mu[0]          1.2e4    2.97  46.92  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4     2.3  36.33  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[2]          1.3e4    2.67  42.14  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.06  48.41  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4     3.0   47.4  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[5]         8534.4    1.12  17.69 8498.2 8522.5 8533.6 8545.7 8568.9    250    1.0\n",
      "mu[6]         7485.7    1.07  14.23 7458.7 7477.4 7485.6 7496.3 7511.6    177   1.01\n",
      "mu_weekend    8069.4   34.05 440.08 7119.2 7814.2 8089.9 8324.3 8998.5    167   1.01\n",
      "mu_workday     1.3e4    24.2 382.59  1.2e4  1.2e4  1.3e4  1.3e4  1.4e4    250    1.0\n",
      "sigma_weekend 630.47    8.01 113.29 417.78 559.17 626.37 694.31 882.33    200    1.0\n",
      "sigma_workday 811.47   11.31 178.78 485.39 694.84 820.82 914.24 1214.0    250    1.0\n",
      "loglik        -55.74  5.7e-3   0.09 -55.92 -55.79 -55.73 -55.69 -55.55    250    1.0\n",
      "y_pred[0]      1.3e4   60.36 954.45  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "y_pred[1]      1.3e4   84.16 1265.1  1.0e4  1.2e4  1.3e4  1.4e4  1.5e4    226   1.01\n",
      "y_pred[2]      1.3e4   73.46 1161.5  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[3]     8496.4   31.29 494.75 7531.0 8126.9 8554.5 8835.0 9423.9    250    1.0\n",
      "y_pred[4]     7456.5   24.28 383.92 6675.9 7231.0 7440.5 7667.1 8301.0    250    1.0\n",
      "y_pred[5]      1.2e4   89.75 1227.3 9642.4  1.1e4  1.2e4  1.3e4  1.5e4    187    1.0\n",
      "y_pred[6]      1.3e4    65.6 1037.1  1.1e4  1.3e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "lp__           4.5e8    0.34   3.38  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8    100    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 15:54:52 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "0 of 250 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': True, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### All convergence checks passed successfully. #####\n",
      "Inference for Stan model: anon_model_1f5534f9f16a420dad5dd0b0607ea807.\n",
      "1 chains, each with iter=500; warmup=250; thin=1; \n",
      "post-warmup draws per chain=250, total post-warmup draws=250.\n",
      "\n",
      "                mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "common_phi    171.25    0.98  10.15 149.77 164.98 171.98 177.71 189.56    107    1.0\n",
      "phi[0]         87.19     0.3   4.77   78.1  84.23   87.4  90.61  95.97    250    1.0\n",
      "phi[1]        171.31     0.8   8.37 155.37 166.38 171.13  176.6 187.68    110    1.0\n",
      "phi[2]        175.66     0.8   9.28 157.28  169.8 175.52 180.93 194.53    134   1.01\n",
      "phi[3]         96.33    0.56   5.44  86.51  92.31  96.18  99.99 108.44     96    1.0\n",
      "phi[4]        145.44    0.58   8.18 130.88 139.49 144.89 150.95 162.64    201   1.01\n",
      "phi[5]        295.44    1.41  17.58 262.78 282.71 293.68 307.53 333.19    156   1.01\n",
      "phi[6]        385.17    1.48  23.38 337.27 369.82 385.72 401.23 429.82    250    1.0\n",
      "mu[0]          1.2e4    3.28  51.92  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4    250    1.0\n",
      "mu[1]          1.3e4    2.34   37.0  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[2]          1.3e4    2.02  31.96  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[3]          1.3e4    3.24   51.3  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[4]          1.3e4    2.77  43.77  1.3e4  1.3e4  1.3e4  1.3e4  1.3e4    250    1.0\n",
      "mu[5]         8534.5    1.14  18.01 8498.0 8522.2 8536.7 8547.3 8568.5    250    1.0\n",
      "mu[6]         7484.5    0.88  13.95 7454.7 7476.6 7484.2 7494.5 7511.1    250    1.0\n",
      "mu_weekend    8030.3   35.65 433.76 7192.0 7737.7 8031.8 8352.9 8906.7    148    1.0\n",
      "mu_workday     1.3e4   23.01 352.68  1.2e4  1.3e4  1.3e4  1.3e4  1.3e4    235    1.0\n",
      "sigma_weekend 629.72    9.34 131.06 387.49 537.76 627.76 716.48 897.07    197    1.0\n",
      "sigma_workday 793.88   10.78 170.41 506.04  669.7 784.33 921.51 1126.5    250    1.0\n",
      "loglik        -55.22  4.7e-3   0.08 -55.37 -55.27 -55.22 -55.17 -55.08    250   1.01\n",
      "y_pred[0]      1.3e4   72.34 1058.2  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    214   1.01\n",
      "y_pred[1]      1.3e4    87.8 1388.2  1.0e4  1.2e4  1.3e4  1.4e4  1.6e4    250    1.0\n",
      "y_pred[2]      1.3e4   66.97 1039.6  1.1e4  1.2e4  1.3e4  1.3e4  1.5e4    241    1.0\n",
      "y_pred[3]     8537.5   32.37 511.86 7557.1 8173.8 8550.5 8859.0 9526.6    250    1.0\n",
      "y_pred[4]     7519.1   25.17 398.01 6729.2 7262.6 7515.5 7742.1 8323.6    250    1.0\n",
      "y_pred[5]      1.2e4   79.59 1258.4 9648.7  1.1e4  1.2e4  1.3e4  1.5e4    250    1.0\n",
      "y_pred[6]      1.3e4   61.43 971.33  1.1e4  1.2e4  1.3e4  1.4e4  1.5e4    250    1.0\n",
      "lp__           4.5e8    0.31    3.1  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8     99    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu Apr 12 16:22:15 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "Run again with max_depth set to a larger value to avoid saturation\n",
      "183 of 250 iterations saturated the maximum tree depth of 10 (73.2%)\n",
      "0.0 of 250 iterations ended with a divergence (0.0%)\n",
      "{'all_rhat_small_enough(fit)': True, 'e_bfmi_all_low_enough(fit)': True, 'max_treedepth_exceeded(fit) < 0.02': False, 'fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3': True}\n",
      "##### Some convergence checks failed, see above. #####\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fit_stan_model_on_sliding_windows(\n",
    "    500,\n",
    "    hier_negbin_data_extractor,\n",
    "    'fit_hier_negbin_one_phi', \n",
    "    model_hier_negbin,\n",
    "    52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
