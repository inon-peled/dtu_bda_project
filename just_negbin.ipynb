{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Commonly Used Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import pystan\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 16, 10\n",
    "COMMON_SEED = 1234\n",
    "\n",
    "def check_convergence(fit, also_print=False):\n",
    "    report = print if also_print else lambda x: None\n",
    "    \n",
    "    def all_rhat_small_enough(fit):\n",
    "        return all(dict(fit.summary())['summary'][:, -1] < 1.1)\n",
    "    \n",
    "    def max_treedepth_exceeded(fit, max_depth = 10):\n",
    "        \"\"\"Check transitions that ended prematurely due to maximum tree depth limit\"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        depths = [x for y in sampler_params for x in y['treedepth__']]\n",
    "        n = sum(1 for x in depths if x == max_depth)\n",
    "        if n > 0:\n",
    "            report('Run again with max_depth set to a larger value to avoid saturation')        \n",
    "        N = len(depths)\n",
    "        report(('{} of {} iterations saturated the maximum tree depth of {}'\n",
    "               + ' ({}%)').format(n, N, max_depth, 100 * n / N))\n",
    "        return float(n) / N\n",
    "    \n",
    "    def e_bfmi_all_low_enough(fit):\n",
    "        \"\"\"\n",
    "        Checks the energy Bayesian fraction of missing information (E-BFMI).\n",
    "        E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
    "        \"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        for chain_num, s in enumerate(sampler_params):\n",
    "            energies = s['energy__']\n",
    "            numer = sum((energies[i] - energies[i - 1])**2 for i in range(1, len(energies))) / len(energies)\n",
    "            denom = np.var(energies)\n",
    "            if numer / denom < 0.2:\n",
    "                report('Chain {}: E-BFMI = {}'.format(chain_num, numer / denom))\n",
    "                report('E-BFMI below 0.2 indicates you may need to reparameterize your model')\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fraction_of_transitions_which_ended_with_divergence(fit):\n",
    "        \"\"\"Check transitions that ended with a divergence\"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        divergent = [x for y in sampler_params for x in y['divergent__']]\n",
    "        n = sum(divergent)\n",
    "        N = len(divergent)\n",
    "        report('{} of {} iterations ended with a divergence ({}%)'\n",
    "              .format(n, N, 100 * n / N))\n",
    "        if n > 0:\n",
    "            report('Try running with larger adapt_delta to remove the divergences')\n",
    "        return n / N\n",
    "    \n",
    "    print(\"all_rhat_small_enough:\", all_rhat_small_enough(fit))\n",
    "    print(\"max_treedepth_exceeded:\", max_treedepth_exceeded(fit) < 0.02)\n",
    "    print(\"e_bfmi_all_low_enough\", e_bfmi_all_low_enough(fit))\n",
    "    print(\"fraction_of_transitions_which_ended_with_divergence\", \\\n",
    "          fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3)\n",
    "#     report(\"##### All convergence checks passed successfully. #####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>births</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>8656</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>7724</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>362</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>12811</td>\n",
       "      <td>Monday</td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13634</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>11990</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  month  day  day_of_week  births weekday_name  day_of_year  \\\n",
       "2014-12-27  2014     12   27            6    8656     Saturday          361   \n",
       "2014-12-28  2014     12   28            7    7724       Sunday          362   \n",
       "2014-12-29  2014     12   29            1   12811       Monday          363   \n",
       "2014-12-30  2014     12   30            2   13634      Tuesday          364   \n",
       "2014-12-31  2014     12   31            3   11990    Wednesday          365   \n",
       "\n",
       "            week_of_year  \n",
       "2014-12-27            52  \n",
       "2014-12-28            52  \n",
       "2014-12-29             1  \n",
       "2014-12-30             1  \n",
       "2014-12-31             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births_2000s_df = pd.read_csv('US_births_2000-2014_SSA.csv')\n",
    "births_2000s_df_with_index = births_2000s_df\\\n",
    "    .rename(columns={'date_of_month': 'day'})\\\n",
    "    .set_index(pd.to_datetime(\n",
    "        births_2000s_df.rename(columns={'date_of_month': 'day'})\n",
    "        [['year', 'month', 'day']]))\\\n",
    "    .assign(weekday_name=lambda df: df.index.weekday_name)\\\n",
    "    .assign(day_of_year=lambda df: df.index.dayofyear)\\\n",
    "    .assign(week_of_year=lambda df: df.index.weekofyear)\n",
    "births_2000s_df_with_index.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11514.461538</td>\n",
       "      <td>1036.715902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12870.846154</td>\n",
       "      <td>790.289954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12762.269231</td>\n",
       "      <td>422.905919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12735.461538</td>\n",
       "      <td>813.567006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12524.500000</td>\n",
       "      <td>634.105530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9049.830189</td>\n",
       "      <td>344.643056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8014.433962</td>\n",
       "      <td>310.302366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean          std\n",
       "day_of_week                           \n",
       "1            11514.461538  1036.715902\n",
       "2            12870.846154   790.289954\n",
       "3            12762.269231   422.905919\n",
       "4            12735.461538   813.567006\n",
       "5            12524.500000   634.105530\n",
       "6             9049.830189   344.643056\n",
       "7             8014.433962   310.302366"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weekday_priors_by_year_2000():\n",
    "    df_2000 = births_2000s_df_with_index[lambda df: df.year == 2000]\n",
    "    return df_2000.groupby('day_of_week').agg(['mean', 'std']).births\n",
    "\n",
    "weekday_priors_by_year_2000()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_test': array([3, 4, 5, 6, 7, 1, 2]),\n",
       " 'x_train': array([1, 2, 3, ..., 7, 1, 2]),\n",
       " 'y_test': array([ 8018, 11171, 12317,  8199,  7174, 11400, 12310]),\n",
       " 'y_train': array([ 7663, 10635, 12449, ...,  7896, 13096, 12525])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_and_test_for_sliding_window(test_date):\n",
    "    num_data_points_before_first_test_date = datetime(2014, 1, 1) - datetime(2001, 1, 1)\n",
    "    df = births_2000s_df_with_index[['day_of_week', 'births']]\\\n",
    "        [lambda df: df.index <= test_date + timedelta(days=6)]\\\n",
    "        [lambda df: df.index >= test_date - num_data_points_before_first_test_date]\n",
    "    return {\n",
    "        'x_train': df.day_of_week[:-7].values,\n",
    "        'y_train': df.births[:-7].values,\n",
    "        'x_test': df.day_of_week[-7:].values,\n",
    "        'y_test': df.births[-7:].values\n",
    "    }\n",
    "        \n",
    "get_train_and_test_for_sliding_window(datetime(2014, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction_errors):\n",
    "    return (prediction_errors ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stan_model_on_sliding_windows(iterations, stan_data_extractor, persist_path, stan_model, num_windows):\n",
    "    if not os.path.exists(persist_path):\n",
    "        os.mkdir(persist_path)\n",
    "    all_prediction_errors = []\n",
    "    for i in range(num_windows):\n",
    "        data = get_train_and_test_for_sliding_window(datetime(2014, 1, 1) + timedelta(days=i * 7))\n",
    "        fit = stan_model.sampling(seed=COMMON_SEED, data=stan_data_extractor(data), iter=iterations, chains=1,\n",
    "                                 control=dict(adapt_delta=0.99))  # max_treedepth=20\n",
    "        print(fit)\n",
    "        check_convergence(fit, also_print=True)\n",
    "        pred_err = fit.extract()['y_pred'].mean(axis=0) - data['y_test']\n",
    "        all_prediction_errors.append(pred_err)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_summary.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit.summary(), f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_extract.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit.extract(), f)         \n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_pred_err.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(pred_err, f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_y_test.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(data['y_test'], f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit, f)                        \n",
    "    return rmse(np.concatenate(all_prediction_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>12481.507692</td>\n",
       "      <td>909.221295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>8532.132075</td>\n",
       "      <td>614.062616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean         std\n",
       "is_weekend                          \n",
       "False       12481.507692  909.221295\n",
       "True         8532.132075  614.062616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def priors_for_weekend_vs_workday_by_year_2000():\n",
    "    df_2000 = births_2000s_df_with_index[lambda df: df.year == 2000]\n",
    "    return df_2000\\\n",
    "        .assign(is_weekend=lambda df: df.day_of_week.isin([6, 7]))\\\n",
    "        .groupby('is_weekend')\\\n",
    "        .agg(['mean', 'std'])\\\n",
    "        .births\n",
    "\n",
    "priors_for_weekend_vs_workday_by_year_2000()\n",
    "# priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == True]['mean'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_workday = 191.338343, phi_weekend = 197.528428\n"
     ]
    }
   ],
   "source": [
    "def negbin_phi(mean, std):\n",
    "    return (mean ** 2) / ((std ** 2) - mean)\n",
    "\n",
    "print(\"phi_workday = %f, phi_weekend = %f\" % (\n",
    "    negbin_phi(12481.507692, 909.221295), negbin_phi(8532.132075, 614.062616)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_cb08a68148c2fe2db013b339a833e4f7 NOW.\n"
     ]
    }
   ],
   "source": [
    "model_even_simpler_hier_negbin = pystan.StanModel(model_code='''\n",
    "data {\n",
    "    int<lower=0> T; // Number of predictions.\n",
    "    int<lower=0> N; // Number of data points.\n",
    "    int y_train[N]; // Train data points.\n",
    "    int y_test[T]; // Test data points, for log-likelihood.\n",
    "    int<lower=1,upper=7> x_train[N]; // Weekday indicator for each observed data point.\n",
    "    int<lower=1,upper=7> x_test[T]; // Weekday indicator for each prediction.\n",
    "}\n",
    "parameters {\n",
    "    real<lower=1> phi[7]; // Prevent too low phi, which yields enormous variance in NegBin.\n",
    "    real<lower=0> mu[7];\n",
    "    real<lower=0> phi_weekend;\n",
    "    real<lower=0> phi_workday;    \n",
    "    real<lower=0> mu_weekend;\n",
    "    real<lower=0> mu_workday;\n",
    "    real<lower=0> sigma_mu_weekend;\n",
    "    real<lower=0> sigma_mu_workday;\n",
    "    real<lower=0> sigma_phi_weekend;\n",
    "    real<lower=0> sigma_phi_workday;\n",
    "}\n",
    "model {\n",
    "    mu_weekend ~ normal(8532, 10);\n",
    "    mu_workday ~ normal(12482, 10);\n",
    "    sigma_mu_weekend ~ cauchy(614, 10);\n",
    "    sigma_mu_workday ~ cauchy(909, 10);\n",
    "    mu[6] ~ normal(mu_weekend, sigma_mu_weekend);\n",
    "    mu[7] ~ normal(mu_weekend, sigma_mu_weekend);\n",
    "    for (i in 1:5) {\n",
    "        mu[i] ~ normal(mu_workday, sigma_mu_workday);\n",
    "    }\n",
    "    \n",
    "    phi_weekend ~ normal(197.528428, 10);\n",
    "    sigma_phi_weekend ~ cauchy(0, 10);\n",
    "    phi[6] ~ normal(phi_weekend, sigma_phi_weekend);\n",
    "    phi[7] ~ normal(phi_weekend, sigma_phi_weekend);\n",
    "    \n",
    "    phi_workday ~ normal(191.338343, 10);\n",
    "    sigma_phi_workday ~ cauchy(0, 10);    \n",
    "    for (i in 1:5) {\n",
    "        phi[i] ~ normal(phi_workday, sigma_phi_workday);\n",
    "    }    \n",
    "    \n",
    "    y_train ~ neg_binomial_2(mu[x_train], phi[x_train]);\n",
    "}\n",
    "generated quantities {\n",
    "    real loglik;\n",
    "    vector[T] y_pred;\n",
    "    loglik = 0;\n",
    "    for (t in 1:T) {\n",
    "        y_pred[t] = neg_binomial_2_rng(mu[x_test[t]], phi[x_test[t]]);\n",
    "        loglik += neg_binomial_2_lpmf(y_test[t] | mu[x_test[t]], phi[x_test[t]]);\n",
    "    }\n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_even_simpler_hier_negbin.pkl', 'wb') as f:\n",
    "    pickle.dump(model_even_simpler_hier_negbin, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_even_simpler_hier_negbin = pickle.load(open('model_even_simpler_hier_negbin.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_cb08a68148c2fe2db013b339a833e4f7.\n",
      "1 chains, each with iter=400; warmup=200; thin=1; \n",
      "post-warmup draws per chain=200, total post-warmup draws=200.\n",
      "\n",
      "                    mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "phi[0]               1.2  7.4e-4 1.3e-3    1.2    1.2    1.2   1.21   1.21      3    nan\n",
      "phi[1]               1.2  9.8e-4 1.4e-3    1.2    1.2    1.2    1.2    1.2      2    nan\n",
      "phi[2]              1.14  7.1e-4 1.2e-3   1.14   1.14   1.14   1.14   1.14      3    nan\n",
      "phi[3]              1.06  1.5e-4 3.2e-4   1.06   1.06   1.06   1.06   1.06      5    nan\n",
      "phi[4]              1.21  1.6e-3 2.3e-3   1.21   1.21   1.21   1.21   1.22      2   2.92\n",
      "phi[5]              1.09  1.3e-4 3.7e-4   1.09   1.09   1.09   1.09   1.09      8    nan\n",
      "phi[6]               1.1  1.0e-4 3.3e-4    1.1    1.1    1.1    1.1    1.1     10    nan\n",
      "mu[0]              1.0e4    45.3  90.59  1.0e4  1.0e4  1.0e4  1.1e4  1.1e4      4   1.34\n",
      "mu[1]              1.2e4   23.88  47.76  1.2e4  1.2e4  1.2e4  1.3e4  1.3e4      4   1.75\n",
      "mu[2]              1.2e4   59.71 103.41  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4      3   3.32\n",
      "mu[3]              1.2e4   63.47 109.94  1.1e4  1.1e4  1.1e4  1.2e4  1.2e4      3   2.28\n",
      "mu[4]              1.2e4   22.66  59.95  1.2e4  1.2e4  1.2e4  1.2e4  1.2e4      7    1.0\n",
      "mu[5]             6987.7   36.89   63.9 6917.1 6938.0 6941.1 7037.2 7137.4      3   2.18\n",
      "mu[6]             6230.2   46.87  81.18 6154.8 6159.5 6193.8 6316.6 6381.4      3   2.23\n",
      "phi_weekend         3.68  6.8e-3   0.02   3.66   3.68   3.68   3.69   3.73      7    1.1\n",
      "phi_workday         1.33  1.3e-3 4.3e-3   1.32   1.33   1.33   1.33   1.34     11   1.01\n",
      "mu_weekend          2.87    0.02   0.03   2.84   2.84   2.86    2.9   2.91      2    4.1\n",
      "mu_workday        9628.5  2488.3 5564.0 331.55 481.08  1.2e4  1.2e4  1.7e4      5    1.3\n",
      "sigma_mu_weekend  721.89    2.46   5.51 716.07 718.66  720.0  723.3 740.93      5    1.6\n",
      "sigma_mu_workday  2160.4    1.51   5.83 2145.9 2159.2 2161.5 2162.2 2171.9     15   1.01\n",
      "sigma_phi_weekend   0.62  1.0e-3 2.3e-3   0.62   0.62   0.62   0.62   0.63      5   1.34\n",
      "sigma_phi_workday    0.2  5.0e-410.0e-4    0.2    0.2    0.2    0.2   0.21      4    nan\n",
      "loglik            -70.96  4.4e-3 6.3e-3 -70.96 -70.96 -70.96 -70.95 -70.95      2   4.33\n",
      "y_pred[0]          1.3e4  980.64  1.3e4 546.55 3446.7 8281.5  1.7e4  4.7e4    183    1.0\n",
      "y_pred[1]          1.1e4   770.1  1.1e4 299.93 2835.9 7019.5  1.5e4  4.0e4    200    1.0\n",
      "y_pred[2]          1.2e4  803.73  1.1e4 223.52 3766.7 9055.0  1.8e4  4.2e4    200    1.0\n",
      "y_pred[3]         6312.4  393.98 5529.7 258.24 2098.0 4682.0 9436.5  2.0e4    197    1.0\n",
      "y_pred[4]         6581.3   433.9 6136.2 245.93 2263.4 4994.5 8382.9  2.2e4    200    1.0\n",
      "y_pred[5]          1.0e4  625.01 8838.9 352.86 3676.7 8434.0  1.4e4  3.3e4    200    1.0\n",
      "y_pred[6]          1.3e4  1133.5  1.2e4 270.73 4247.3 8962.5  1.7e4  4.8e4    115    1.0\n",
      "lp__               4.5e8   1.6e5  3.2e5  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8      4   1.48\n",
      "\n",
      "Samples were drawn using NUTS at Tue Apr 10 15:00:19 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "all_rhat_small_enough: False\n",
      "Run again with max_depth set to a larger value to avoid saturation\n",
      "125 of 200 iterations saturated the maximum tree depth of 10 (62.5%)\n",
      "max_treedepth_exceeded: False\n",
      "Chain 0: E-BFMI = 0.017220976302262943\n",
      "E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
      "e_bfmi_all_low_enough False\n",
      "0.0 of 200 iterations ended with a divergence (0.0%)\n",
      "fraction_of_transitions_which_ended_with_divergence True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inonpe/jupyter/dtu_bda_project/env/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1921.8214752555898"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_stan_model_on_sliding_windows(\n",
    "    400,\n",
    "    lambda data: dict(\n",
    "        x_train=data['x_train'],\n",
    "        x_test=data['x_test'],\n",
    "        y_train=data['y_train'],\n",
    "        y_test=data['y_test'],\n",
    "        T=7,\n",
    "        N=len(data['x_train'])),\n",
    "    'fit_even_simpler_hier_negbin', model_even_simpler_hier_negbin, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
