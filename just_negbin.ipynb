{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Commonly Used Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "import pystan\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 16, 10\n",
    "COMMON_SEED = 1234\n",
    "\n",
    "def check_convergence(fit, also_print=False):\n",
    "    report = print if also_print else lambda x: None\n",
    "    \n",
    "    def all_rhat_small_enough(fit):\n",
    "        return all(dict(fit.summary())['summary'][:, -1] < 1.1)\n",
    "    \n",
    "    def max_treedepth_exceeded(fit, max_depth = 10):\n",
    "        \"\"\"Check transitions that ended prematurely due to maximum tree depth limit\"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        depths = [x for y in sampler_params for x in y['treedepth__']]\n",
    "        n = sum(1 for x in depths if x == max_depth)\n",
    "        if n > 0:\n",
    "            report('Run again with max_depth set to a larger value to avoid saturation')        \n",
    "        N = len(depths)\n",
    "        report(('{} of {} iterations saturated the maximum tree depth of {}'\n",
    "               + ' ({}%)').format(n, N, max_depth, 100 * n / N))\n",
    "        return float(n) / N\n",
    "    \n",
    "    def e_bfmi_all_low_enough(fit):\n",
    "        \"\"\"\n",
    "        Checks the energy Bayesian fraction of missing information (E-BFMI).\n",
    "        E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
    "        \"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        for chain_num, s in enumerate(sampler_params):\n",
    "            energies = s['energy__']\n",
    "            numer = sum((energies[i] - energies[i - 1])**2 for i in range(1, len(energies))) / len(energies)\n",
    "            denom = np.var(energies)\n",
    "            if numer / denom < 0.2:\n",
    "                report('Chain {}: E-BFMI = {}'.format(chain_num, numer / denom))\n",
    "                report('E-BFMI below 0.2 indicates you may need to reparameterize your model')\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fraction_of_transitions_which_ended_with_divergence(fit):\n",
    "        \"\"\"Check transitions that ended with a divergence\"\"\"\n",
    "        sampler_params = fit.get_sampler_params(inc_warmup=False)\n",
    "        divergent = [x for y in sampler_params for x in y['divergent__']]\n",
    "        n = sum(divergent)\n",
    "        N = len(divergent)\n",
    "        report('{} of {} iterations ended with a divergence ({}%)'\n",
    "              .format(n, N, 100 * n / N))\n",
    "        if n > 0:\n",
    "            report('Try running with larger adapt_delta to remove the divergences')\n",
    "        return n / N\n",
    "    \n",
    "    print(\"all_rhat_small_enough:\", all_rhat_small_enough(fit))\n",
    "    print(\"max_treedepth_exceeded:\", max_treedepth_exceeded(fit) < 0.02)\n",
    "    print(\"e_bfmi_all_low_enough\", e_bfmi_all_low_enough(fit))\n",
    "    print(\"fraction_of_transitions_which_ended_with_divergence\", \\\n",
    "          fraction_of_transitions_which_ended_with_divergence(fit) <= 5E-3)\n",
    "#     report(\"##### All convergence checks passed successfully. #####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>births</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>8656</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>7724</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>362</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>12811</td>\n",
       "      <td>Monday</td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>13634</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>11990</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year  month  day  day_of_week  births weekday_name  day_of_year  \\\n",
       "2014-12-27  2014     12   27            6    8656     Saturday          361   \n",
       "2014-12-28  2014     12   28            7    7724       Sunday          362   \n",
       "2014-12-29  2014     12   29            1   12811       Monday          363   \n",
       "2014-12-30  2014     12   30            2   13634      Tuesday          364   \n",
       "2014-12-31  2014     12   31            3   11990    Wednesday          365   \n",
       "\n",
       "            week_of_year  \n",
       "2014-12-27            52  \n",
       "2014-12-28            52  \n",
       "2014-12-29             1  \n",
       "2014-12-30             1  \n",
       "2014-12-31             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "births_2000s_df = pd.read_csv('US_births_2000-2014_SSA.csv')\n",
    "births_2000s_df_with_index = births_2000s_df\\\n",
    "    .rename(columns={'date_of_month': 'day'})\\\n",
    "    .set_index(pd.to_datetime(\n",
    "        births_2000s_df.rename(columns={'date_of_month': 'day'})\n",
    "        [['year', 'month', 'day']]))\\\n",
    "    .assign(weekday_name=lambda df: df.index.weekday_name)\\\n",
    "    .assign(day_of_year=lambda df: df.index.dayofyear)\\\n",
    "    .assign(week_of_year=lambda df: df.index.weekofyear)\n",
    "births_2000s_df_with_index.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11514.461538</td>\n",
       "      <td>1036.715902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12870.846154</td>\n",
       "      <td>790.289954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12762.269231</td>\n",
       "      <td>422.905919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12735.461538</td>\n",
       "      <td>813.567006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12524.500000</td>\n",
       "      <td>634.105530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9049.830189</td>\n",
       "      <td>344.643056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8014.433962</td>\n",
       "      <td>310.302366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean          std\n",
       "day_of_week                           \n",
       "1            11514.461538  1036.715902\n",
       "2            12870.846154   790.289954\n",
       "3            12762.269231   422.905919\n",
       "4            12735.461538   813.567006\n",
       "5            12524.500000   634.105530\n",
       "6             9049.830189   344.643056\n",
       "7             8014.433962   310.302366"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weekday_priors_by_year_2000():\n",
    "    df_2000 = births_2000s_df_with_index[lambda df: df.year == 2000]\n",
    "    return df_2000.groupby('day_of_week').agg(['mean', 'std']).births\n",
    "\n",
    "weekday_priors_by_year_2000()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_test': array([3, 4, 5, 6, 7, 1, 2]),\n",
       " 'x_train': array([1, 2, 3, ..., 7, 1, 2]),\n",
       " 'y_test': array([ 8018, 11171, 12317,  8199,  7174, 11400, 12310]),\n",
       " 'y_train': array([ 7663, 10635, 12449, ...,  7896, 13096, 12525])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_and_test_for_sliding_window(test_date):\n",
    "    num_data_points_before_first_test_date = datetime(2014, 1, 1) - datetime(2001, 1, 1)\n",
    "    df = births_2000s_df_with_index[['day_of_week', 'births']]\\\n",
    "        [lambda df: df.index <= test_date + timedelta(days=6)]\\\n",
    "        [lambda df: df.index >= test_date - num_data_points_before_first_test_date]\n",
    "    return {\n",
    "        'x_train': df.day_of_week[:-7].values,\n",
    "        'y_train': df.births[:-7].values,\n",
    "        'x_test': df.day_of_week[-7:].values,\n",
    "        'y_test': df.births[-7:].values\n",
    "    }\n",
    "        \n",
    "get_train_and_test_for_sliding_window(datetime(2014, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction_errors):\n",
    "    return (prediction_errors ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stan_model_on_sliding_windows(iterations, stan_data_extractor, persist_path, stan_model, num_windows):\n",
    "    if not os.path.exists(persist_path):\n",
    "        os.mkdir(persist_path)\n",
    "    all_prediction_errors = []\n",
    "    for i in range(num_windows):\n",
    "        data = get_train_and_test_for_sliding_window(datetime(2014, 1, 1) + timedelta(days=i * 7))\n",
    "        fit = stan_model.sampling(seed=COMMON_SEED, data=stan_data_extractor(data), iter=iterations, chains=1,\n",
    "                                 control=dict(adapt_delta=0.99))  # max_treedepth=20\n",
    "        print(fit)\n",
    "        check_convergence(fit, also_print=True)\n",
    "        pred_err = fit.extract()['y_pred'].mean(axis=0) - data['y_test']\n",
    "        all_prediction_errors.append(pred_err)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_summary.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit.summary(), f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_extract.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit.extract(), f)         \n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_pred_err.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(pred_err, f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d_y_test.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(data['y_test'], f)\n",
    "        with gzip.open(os.path.join(persist_path, 'fit%d.pkl.gz' % i), 'wb') as f:\n",
    "            pickle.dump(fit, f)                        \n",
    "    return rmse(np.concatenate(all_prediction_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>12481.507692</td>\n",
       "      <td>909.221295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>8532.132075</td>\n",
       "      <td>614.062616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean         std\n",
       "is_weekend                          \n",
       "False       12481.507692  909.221295\n",
       "True         8532.132075  614.062616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def priors_for_weekend_vs_workday_by_year_2000():\n",
    "    df_2000 = births_2000s_df_with_index[lambda df: df.year == 2000]\n",
    "    return df_2000\\\n",
    "        .assign(is_weekend=lambda df: df.day_of_week.isin([6, 7]))\\\n",
    "        .groupby('is_weekend')\\\n",
    "        .agg(['mean', 'std'])\\\n",
    "        .births\n",
    "\n",
    "priors_for_weekend_vs_workday_by_year_2000()\n",
    "# priors_for_weekend_vs_workday_by_year_2000()[lambda df: df.index == True]['mean'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_2e1ff531a6913631bda4622f8ce9a981 NOW.\n"
     ]
    }
   ],
   "source": [
    "model_even_simpler_hier_negbin = pystan.StanModel(model_code='''\n",
    "data {\n",
    "    int<lower=0> T; // Number of predictions.\n",
    "    int<lower=0> N; // Number of data points.\n",
    "    int y_train[N]; // Train data points.\n",
    "    int y_test[T]; // Test data points, for log-likelihood.\n",
    "    int<lower=1,upper=7> x_train[N]; // Weekday indicator for each observed data point.\n",
    "    int<lower=1,upper=7> x_test[T]; // Weekday indicator for each prediction.\n",
    "}\n",
    "parameters {\n",
    "    real<lower=1> phi[7]; // Prevent too low phi, which yields enormous variance in NegBin.\n",
    "    real<lower=0> mu[7];\n",
    "    real<lower=0> phi_weekend;\n",
    "    real<lower=0> phi_workday;    \n",
    "    real<lower=0> mu_weekend;\n",
    "    real<lower=0> mu_workday;\n",
    "    real<lower=0> sigma_mu_weekend;\n",
    "    real<lower=0> sigma_mu_workday;\n",
    "    real<lower=0> sigma_phi_weekend;\n",
    "    real<lower=0> sigma_phi_workday;\n",
    "}\n",
    "model {\n",
    "    mu_weekend ~ normal(8532, 10);\n",
    "    mu_workday ~ normal(12482, 10);\n",
    "    sigma_mu_weekend ~ cauchy(614, 10);\n",
    "    sigma_mu_workday ~ cauchy(909, 10);\n",
    "    mu[6] ~ normal(mu_weekend, sigma_mu_weekend);\n",
    "    mu[7] ~ normal(mu_weekend, sigma_mu_weekend);\n",
    "    for (i in 1:5) {\n",
    "        mu[i] ~ normal(mu_workday, sigma_mu_workday);\n",
    "    }\n",
    "    \n",
    "    phi_weekend ~ normal(200, 10);\n",
    "    sigma_phi_weekend ~ cauchy(0, 10);\n",
    "    \n",
    "    phi[6] ~ normal(phi_weekend, sigma_phi_weekend);\n",
    "    phi[7] ~ normal(phi_weekend, sigma_phi_weekend);\n",
    "    \n",
    "    phi_workday ~ normal(200, 10);\n",
    "    sigma_phi_workday ~ cauchy(0, 10);    \n",
    "    for (i in 1:5) {\n",
    "        phi[i] ~ normal(phi_workday, sigma_phi_workday);\n",
    "    }    \n",
    "    \n",
    "    y_train ~ neg_binomial_2(mu[x_train], phi[x_train]);\n",
    "}\n",
    "generated quantities {\n",
    "    real loglik;\n",
    "    vector[T] y_pred;\n",
    "    loglik = 0;\n",
    "    for (t in 1:T) {\n",
    "        y_pred[t] = neg_binomial_2_rng(mu[x_test[t]], phi[x_test[t]]);\n",
    "        loglik += neg_binomial_2_lpmf(y_test[t] | mu[x_test[t]], phi[x_test[t]]);\n",
    "    }\n",
    "}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_even_simpler_hier_negbin.pkl', 'wb') as f:\n",
    "    pickle.dump(model_even_simpler_hier_negbin, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_even_simpler_hier_negbin = pickle.load(open('model_even_simpler_hier_negbin.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_2e1ff531a6913631bda4622f8ce9a981.\n",
      "1 chains, each with iter=100; warmup=50; thin=1; \n",
      "post-warmup draws per chain=50, total post-warmup draws=50.\n",
      "\n",
      "                    mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "phi[0]              1.16  4.9e-3 8.4e-3   1.14   1.15   1.16   1.16   1.16      3   1.68\n",
      "phi[1]              1.17  3.2e-3 6.5e-3   1.16   1.17   1.18   1.18   1.18      4   1.21\n",
      "phi[2]              1.17  8.2e-3   0.02   1.13   1.17   1.18   1.18   1.18      4   1.32\n",
      "phi[3]              1.06  4.4e-4 1.1e-3   1.06   1.06   1.06   1.06   1.06      6   1.13\n",
      "phi[4]              1.19  3.6e-3 7.1e-3   1.17   1.19   1.19    1.2    1.2      4   1.52\n",
      "phi[5]              1.09  1.7e-3 3.4e-3   1.08   1.09   1.09   1.09   1.09      4   1.62\n",
      "phi[6]               1.1  6.8e-4 1.9e-3    1.1    1.1    1.1    1.1    1.1      8   0.99\n",
      "mu[0]              1.1e4  312.97 625.93 8949.5  1.1e4  1.1e4  1.1e4  1.1e4      4   1.37\n",
      "mu[1]              1.1e4  374.16 748.33 9306.9  1.1e4  1.2e4  1.2e4  1.2e4      4    1.5\n",
      "mu[2]              1.1e4  275.03 614.99 9414.2  1.1e4  1.2e4  1.2e4  1.2e4      5   1.38\n",
      "mu[3]              1.1e4  314.63 629.26 9141.3  1.1e4  1.1e4  1.1e4  1.1e4      4   1.42\n",
      "mu[4]              1.1e4  218.23 534.55 9546.8  1.1e4  1.1e4  1.1e4  1.1e4      6   1.24\n",
      "mu[5]             6652.7  272.65  545.3 5220.0 6498.6 6831.8 7046.6 7080.9      4   1.65\n",
      "mu[6]             5777.7  214.94 429.87 4598.8 5660.4 5966.4 6070.7 6118.6      4   1.55\n",
      "phi_weekend         4.37    0.08   0.16   4.22   4.25   4.33   4.41    4.8      4   1.68\n",
      "phi_workday         1.31  9.2e-3   0.02   1.27   1.29    1.3   1.33   1.35      6   1.59\n",
      "mu_weekend          2.93    0.27   0.46   1.87    2.7   3.15   3.28   3.29      3   1.73\n",
      "mu_workday         20.19    6.33  10.97   3.48    9.6  20.13  31.81  35.18      3   2.71\n",
      "sigma_mu_weekend  547.59   45.65  91.29 308.77 535.32 585.98 603.83 612.97      4   1.45\n",
      "sigma_mu_workday  1641.8  139.71 279.41 945.87 1602.9 1802.2 1812.7 1825.5      4   1.48\n",
      "sigma_phi_weekend   0.62  6.8e-3   0.02   0.58   0.62   0.62   0.63   0.64      5   1.03\n",
      "sigma_phi_workday    0.2  1.1e-3 3.4e-3   0.19    0.2    0.2    0.2   0.21      9   1.11\n",
      "loglik            -71.03    0.05   0.11 -71.34 -71.03 -70.97 -70.97 -70.97      5    1.3\n",
      "y_pred[0]          1.3e4  2251.3  1.5e4  77.22 3542.1 8385.0  1.7e4  5.4e4     42   0.99\n",
      "y_pred[1]          1.1e4  1323.2 9356.7 154.68 3904.3 8171.5  1.6e4  3.5e4     50   1.04\n",
      "y_pred[2]          1.4e4  2526.3  1.3e4 1327.2 4971.2 9850.5  1.6e4  5.0e4     26   1.06\n",
      "y_pred[3]         6369.9  825.44 5836.7 444.03 2284.6 4488.0 8601.4  2.2e4     50    1.0\n",
      "y_pred[4]         5938.3  973.74 6885.4  248.6 1526.6 5128.0 7626.7  3.0e4     50   1.03\n",
      "y_pred[5]          1.0e4  1438.1 8628.6 223.97 3320.9 8011.5  1.6e4  3.2e4     36   0.98\n",
      "y_pred[6]         9222.5  1227.6 8680.4 387.62 2639.7 6661.5  1.3e4  3.5e4     50   0.98\n",
      "lp__               4.5e8  901.65 1561.7  4.5e8  4.5e8  4.5e8  4.5e8  4.5e8      3    2.5\n",
      "\n",
      "Samples were drawn using NUTS at Tue Apr 10 14:48:24 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n",
      "all_rhat_small_enough: False\n",
      "0 of 50 iterations saturated the maximum tree depth of 10 (0.0%)\n",
      "max_treedepth_exceeded: True\n",
      "Chain 0: E-BFMI = 0.007758731208162147\n",
      "E-BFMI below 0.2 indicates you may need to reparameterize your model\n",
      "e_bfmi_all_low_enough False\n",
      "5.0 of 50 iterations ended with a divergence (10.0%)\n",
      "Try running with larger adapt_delta to remove the divergences\n",
      "fraction_of_transitions_which_ended_with_divergence False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inonpe/jupyter/dtu_bda_project/env/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2570.4699825629446"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_stan_model_on_sliding_windows(\n",
    "    100,\n",
    "    lambda data: dict(\n",
    "        x_train=data['x_train'],\n",
    "        x_test=data['x_test'],\n",
    "        y_train=data['y_train'],\n",
    "        y_test=data['y_test'],\n",
    "        T=7,\n",
    "        N=len(data['x_train'])),\n",
    "    'fit_even_simpler_hier_negbin', model_even_simpler_hier_negbin, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
